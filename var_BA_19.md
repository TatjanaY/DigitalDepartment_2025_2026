# 📈 Анализ аномальных явлений и поведенческих паттернов в странных сообществах (UFO, случайные пиццы и собаки в Цюрихе)

## 🎯 Постановка задачи

В этом кейсе предлагается провести **исследовательский и бизнес-аналитический анализ нестандартных данных**, которые на первый взгляд не имеют прямой коммерческой ценности, но позволяют выявить **поведенческие, географические и социальные закономерности**.

**Цель исследования** — определить:  
- какие **географические и временные паттерны** проявляются в сообщениях об НЛО;  
- какие **факторы текста и контекста** влияют на успех просьбы о помощи (пицца);  
- как **распределяются демографические и геопространственные характеристики** зарегистрированных собак в городе.

> ⚠️ **Важно**: датасеты **не связаны между собой** и представляют **независимые исследовательские блоки**.  
> Их объединяет только методологический подход: **поиск скрытых паттернов в неочевидных данных**.

В рамках кейса необходимо провести **три параллельных анализа**, включая расчёт ключевых метрик: **частота событий, успешность запросов, распределение по районам, тренды во времени**.

**Результатом выполнения задания** должен стать **Jupyter Notebook**, содержащий код, расчёты, функции, визуализации и аналитические выводы.

---

## 📦 Используемые датасеты

В рамках кейса используются **три независимых датасета**, отражающих разные аспекты человеческой и животной активности.

### 📁 Входные данные (обзор)

---

### 📄 Датасет 1 — UFO Sightings Dataset  
**Kaggle:** [https://www.kaggle.com/datasets/NUFORC/ufo-sightings](https://www.kaggle.com/datasets/NUFORC/ufo-sightings)  

**Тип данных:** наблюдения неопознанных летающих объектов  

**Основные признаки:**  
- `datetime` — дата и время наблюдения  
- `city`, `state`, `country` — геолокация  
- `shape` — форма объекта («light», «circle», «triangle» и др.)  
- `duration` — длительность наблюдения  

**Назначение:**  
Используется для анализа **географии, сезонности и типологии** сообщений об НЛО.

---

### 📄 Датасет 2 — Random Acts of Pizza  
**Kaggle:** [https://www.kaggle.com/datasets/kaggle/random-acts-of-pizza](https://www.kaggle.com/datasets/kaggle/random-acts-of-pizza)  

**Тип данных:** просьбы о помощи из сабреддита Reddit  

**Основные признаки:**  
- `request_text` — текст просьбы  
- `requester_received_pizza` — получен ли ответ (`True`/`False`)  
- `request_date` — дата публикации  
- `requester_karma` — репутация автора  
- `text_length` — длина текста  

**Назначение:**  
Позволяет исследовать **факторы успешности социальной просьбы**, включая **текстовые и поведенческие признаки**.

---

### 📄 Датасет 3 — Dogs of Zurich  
**Kaggle:** [https://www.kaggle.com/datasets/kmader/dogs-of-zurich/code](https://www.kaggle.com/datasets/kmader/dogs-of-zurich/code)  

**Тип данных:** реестр зарегистрированных собак в Цюрихе  

**Основные признаки:**  
- `dog_id` — идентификатор  
- `breed` — порода  
- `age` — возраст  
- `gender` — пол  
- `district` — район проживания владельца  

**Назначение:**  
Используется для **геодемографического анализа**, выявления **популярности пород по районам** и **возрастных паттернов**.

---

## 📝 Обязательные разделы итогового Jupyter Notebook

1. Предварительный анализ данных  
2. Предобработка данных  
3. Разработка функций для анализа данных  
4. Разработка функции для формирования исследовательских метрик  
5. Разработка функций расчёта распределений и корреляций  
6. Визуализация ключевых выводов  
7. Исследовательский анализ данных  
8. Интерпретация паттернов и аномалий  
9. Выводы  

---

## 🧩 Структура итогового Jupyter Notebook

### 1. 📊 Предварительный анализ данных  
**Цель раздела:** понять структуру, качество и ограничения данных.  

**Необходимо:**  
- вывести размеры таблиц (`shape`);  
- изучить типы данных (`info`);  
- оценить пропуски (особенно в `shape`, `breed`, `request_text`);  
- проверить аномалии (например, UFO в будущем, возраст собак > 30);  
- кратко описать особенности каждого датасета.  

**В конце раздела:** краткие выводы по данным и их пригодности к анализу.

---

### 2. 🧹 Предобработка данных  
**Цель раздела:** подготовить данные к расчёту метрик и визуализации.  

**Необходимо:**  
- привести все даты к формату `datetime`;  
- нормализовать текст (`request_text`): очистка, приведение к нижнему регистру;  
- обработать пропуски (удаление или импутация);  
- унифицировать географические названия (`country`, `district`);  
- создать производные признаки:  
  - `hour_of_day`, `day_of_week`;  
  - `text_length`, `word_count`;  
  - `age_group` для собак.  

**В конце раздела:** промежуточные выводы о структуре и чистоте итогового датасета.

---

### 3. 🧠 Разработка функций для анализа данных  
**Цель раздела:** создать переиспользуемый аналитический инструментарий.  

**Ключевое правило:**  
> Все функции — расчёта метрик и визуализации — создаются здесь,  
> но **графики строятся и анализируются в отдельном разделе**.

**В этом разделе разрабатываются функции:**

1. **Для агрегации данных:**  
   - по времени (год, месяц, час);  
   - по географии (`country`, `district`);  
   - по категориям (`shape`, `breed`).  

2. **Для фильтрации данных:**  
   - по результату (`requester_received_pizza`);  
   - по типу формы НЛО;  
   - по возрасту собак.  

3. **Для текстовой аналитики:**  
   - подсчёт длины текста;  
   - поиск ключевых слов (`please`, `thank`, `help`);  
   - (опционально) тональность.  

4. **Для расчёта исследовательских метрик:**  
   - частота UFO по регионам;  
   - доля успешных запросов пиццы;  
   - популярность пород по районам.  

5. **Для визуализации:**  
   - time series plot;  
   - geospatial map (при наличии координат);  
   - bar chart;  
   - word cloud;  
   - histogram / boxplot.  

**Структура раздела:**  
- краткое введение в исследовательскую аналитику;  
- реализация функций с аннотациями;  
- перечень функций и их назначение.

---

### 4. 🔍 Формирование исследовательских метрик  

#### 4.1 👽 UFO Sightings  
- количество сообщений по годам и странам;  
- топ-10 форм объектов;  
- средняя длительность наблюдения.  

#### 4.2 🍕 Random Acts of Pizza  
- общая доля успешных запросов;  
- средняя длина текста у успешных/неуспешных;  
- корреляция с `requester_karma`.  

#### 4.3 🐕 Dogs of Zurich  
- распределение пород по районам;  
- средний возраст собак по району;  
- соотношение полов.

---

### 5. 📊 Расчёт распределений и корреляций  

#### 5.1 UFO  
- сезонность (месяцы с наибольшим числом сообщений);  
- связь между `shape` и `country`.  

#### 5.2 Пицца  
- зависимость успеха от времени суток и дня недели;  
- влияние наличия слова «please» на результат.  

#### 5.3 Собаки  
- корреляция между районом и породой;  
- различия в возрасте между породами.

---

### 6. 📉 Визуализация ключевых выводов  
**Цель раздела:** визуально представить и интерпретировать результаты.  

**Визуализации:**  

1. **👽 UFO**  
   - Line chart: количество сообщений по годам (1950–2020);  
   - Bar chart: топ-10 стран по количеству наблюдений;  
   - Pie chart: распределение форм объектов.  

2. **🍕 Пицца**  
   - Bar chart: доля успеха по дням недели;  
   - Scatter plot: X — длина текста, Y — успех, цвет — karma;  
   - Word cloud: наиболее частые слова в успешных запросах.  

3. **🐕 Собаки**  
   - Bar chart: топ-5 пород по районам;  
   - Boxplot: возраст собак по породам;  
   - Heatmap: плотность регистрации по районам (если доступны координаты).  

**В конце раздела:** выводы по визуальному анализу — ключевые паттерны, аномалии, неожиданные связи.

---

### 7. 🔎 Исследовательский анализ данных  
**Цель раздела:** выявить скрытые закономерности.  

**Необходимо:**  
- исследовать пики UFO в культурно значимые годы (например, после фильмов);  
- проанализировать «самые щедрые» периоды на Reddit;  
- выявить «элитные» районы по породам собак;  
- проверить гипотезу: «чем длиннее и вежливее просьба — тем выше шанс успеха».

---

### 8. 🌐 Интерпретация паттернов и аномалий  
**Цель раздела:** перевести данные в социальный контекст.  

**Необходимо:**  
- сформулировать **гипотезы о причинах паттернов** (медиа, культура, демография);  
- предложить **методы верификации** (например, сравнение с данными Google Trends);  
- оценить **потенциал использования таких данных** в маркетинге, urban planning, социологии.

---

### 9. 🧾 Выводы  
В финальном разделе необходимо:  
- сформулировать **ключевые исследовательские инсайты** по каждому датасету;  
- объяснить, **почему «странные» данные могут быть ценными**;  
- предложить **идеи для расширения анализа**:  
  - NLP-анализ текстов просьб;  
  - интеграция UFO с данными о загрязнении неба;  
  - прогноз популярности пород;  
- указать **ограничения исследования** (самоотчётность, отсутствие контрольной группы);  
- обозначить **направления для дальнейшего анализа** (междисциплинарные проекты, A/B-тесты на платформах).

---